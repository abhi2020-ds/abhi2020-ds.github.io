---
layout: post
title:  "Try BeautifulSoup of Sport"
date:   2021-06-20
excerpt: "Python package for parsing HTML and XML code for web scraping"
description: "Beautiful Soup is a python library for extracting data out of HTML and XML files. There are other similar libraries such as Selenium and Scrapy"
image: "/images/BeautifulSoup/Big3.jpeg"
comments_id: 4
categories: blog
author: abhi_03
---
<hr/>
<img align="right"  src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fabhi2020-ds.github.io%2Fblog%2Fwebscrp%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false" width="100" height="25" />
<img align="right" src="https://img.shields.io/badge/Code%20Highlight-Python-green.svg?style=for-the-badge" alt="repo outline" width="150" height="25" />
<br>
<h2>The Big Three</h2>
Year 2008 I was graduating from bachelors program in Computer Science. Soon to be transformed into a working professional. Year 2008 was also the year when I was introduced to my favorite sport Tennis. It has been 13 years now and my passion for this sport is still very much intact. Prior to 2008 I was aware of the game and some famous athletes but never closely followed the game, it was Wimbledon Finals of that year which was a hype train I onboarded for two reasons : 
 - Former World No. 1 Roger Federer was chasing history to tie with Sampras for most grand slams (14) in Mens Tennis
 - Rafael Nadal was on the other side of the court trying to make his mark in Wimbledon Winners after just winning French Open 4th time. He was chasing a rare French Open - Wimbledon double feat which was rare to achieve, since it required player to switch from clay to grass surface , extremely difficult.  
Finals was a classic 4 hr 48 min marathon which Nadal won and marked begining of a rivarly which continued for decades. Novak Djokovic on the other hand had just won his first slam that year in Australian Open. He was still always considered a funny individual, cracking jokes, imitating fellow players, but one who lacked mental temprament to compete with Roger and Rafa. That soon changed when 2011 he started pushing his limits and started winning slams. Today they are called as "The Big 3" of tennis world, sharing total of 59 slams ! 

<hr />  
<blockquote>“I fear no one but respect everyone.” <b> - Roger Federer</b> </blockquote>
<blockquote>“If you don’t lose, you cannot enjoy the victories.” <b> - Rafael Nadal</b> </blockquote>
<blockquote>“Your belief should be stronger than your doubt.”<b> - Novak Djokovic</b> </blockquote>
<hr />

Being passionate about data analytics , I wanted to gather useful data to project their carrer graph and build a race chart showcasing their progression and succession to the top of this sport. After going through several options I decided to use Python as the preferred language to tell this story.

<h2>Why Beautiful Soup?</h2>
<span class="image right"><img src="{{ "/images/BeautifulSoup/BSlogo.jpeg" | absolute_url }}" alt="" /></span> 
Objective for me was to get complete and accurate trend visual, and to get this data from a reliable source, in this case was ATP website, since online repository has history of all tennis players and matches for all tournaments. But how to quickly navigate through web and get this extracted into a sample set? Enters Beautiful Soup, for a quick project turnaround and to scrape literally anything you give to your parser, this library provided by Python is the most diverse package you can ask for. 
- Beautiful Soup makes tree traverse, searching etc. very easy.
- It automatically converts encoding types to best suit your need.
- It sits on top of other Python libraries like lxml and html5lib

Many big data and data science projects require web scraping and this library helps developers, the name of the package was inspired from a song in <i>Alice's Advantures In The Wonderland</i>

<div class="4u"><span class="image fit"><img src="{{ "/images/BeautifulSoup/bsoupref.jpg" | absolute_url }}" alt="" /></span></div>

<h3>Inspecting Web Page </h3>
They key to gathering information from web is understanding tree structure of your target webpage. This helps in extracting information such as query pattern, HTML table content etc. You can use any browser tool to get HTML content view, I used Chrome's Inspect Element feature. 

<span class="image fit"><img src="{{ "/images/BeautifulSoup/Inspect.png" | absolute_url }}" alt="" /></span>

You can inspect DOM and CSS pattern using this feature and understand page tree structure.

<h3>Data Manipulation & Visualization </h3>
Extracting data from a site majority of time would also require transformation. Extracted data needs to be cleaned further for analytics and visualization purpose. This example uses pandas, bar_chart_race and pandas_alive package to achieve these steps.

<h3>Implementation Steps</h3>
<ul>
    <li>Use request library to initiate URL connection</li>
    <li>Use beautiful soup library to find html content from the page</li>
    <li>Store extract in Dataframe using Pandas</li>
    <li>Use race chart and pandas alive library to create a gif and video extract of the data</li>
</ul>

<hr /> 
<div class="row">
    <div class="6u 12u$(small)">
        <h3>References</h3>
        <ul>
            <li><a href="https://bookdown.org/yihui/rmarkdown/">R Markdown</a></li>
            <li><a href="https://support.rstudio.com/hc/en-us/articles/200486468-Authoring-R-Presentations">R Presentations</a></li>
        </ul>
    </div>
    </div>
    
