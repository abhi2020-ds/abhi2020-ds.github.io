---
layout: post
title:  "Try BeautifulSoup of Sport"
date:   2021-06-20
excerpt: "Python package for parsing HTML and XML code for web scraping"
description: "Beautiful Soup is a python library for extracting data out of HTML and XML files. There are other similar libraries such as Selenium and Scrapy"
image: "/images/BeautifulSoup/Big3.jpeg"
comments_id: 4
categories: blog
author: abhi_03
---
<hr/>
<img align="right"  src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fabhi2020-ds.github.io%2Fblog%2Fwebscrp%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false" width="100" height="25" />
<img align="right" src="https://img.shields.io/badge/Code%20Highlight-Python-green.svg?style=for-the-badge" alt="repo outline" width="150" height="25" />
<br>
<h2>The Big Three</h2>
Year 2008 I was finsihing up with my Bachelors in Computer Science. It was also the year when I was introduced to my favorite sport Tennis. It's been 13 years and my passion for this sport is still  intact. In the past I was aware of the game and few famous athletes but never closely followed this game. When Wimbledon finals were building up and it was clear that Federer and Rafa are going to face each other, it was a hype train and I onboard for two reasons : 
 - Former World No. 1 <b>Roger Federer</b> was at that time chasing history, if he won he would  tie with Sampras for most grand slams (14) in Mens Tennis.
 - <b>Rafael Nadal</b>, was knocking on the door to make his mark in Wimbledon Winners after just winning French Open for the 4th time. He was already called by sports pundit, a clay court specialist and <b>King Of Clay</b>. He was chasing a rare French Open - Wimbledon double feat which was rare to achieve, since it required player to switch from clay to grass surface , extremely difficult to switch surfaces, adapt and win it all the way.  

Finals was a classic <b>4 hr 48 mins</b> marathon which Nadal won and marked begining of a rivarly which continued for decades. 

<b>Novak Djokovic</b> on the other hand had just won his first slam that year in Australian Open. He was still always considered a funny individual, cracking jokes, doing spectacular job perfectly imitating other players during post match ceremonies, however he lacked mental temprament to compete with Roger and Rafa. That soon changed when 2011 he started pushing his limits and started winning slams. Today they are called as "The Big 3" of tennis world, sharing total of 59 slams !  


<hr />  
<blockquote>“I fear no one but respect everyone.” <b> - Roger Federer</b> </blockquote>
<blockquote>“If you don’t lose, you cannot enjoy the victories.” <b> - Rafael Nadal</b> </blockquote>
<blockquote>“Your belief should be stronger than your doubt.”<b> - Novak Djokovic</b> </blockquote>
<hr />

Being passionate about data analytics , I wanted to gather useful data to project their carrer graph and build a race chart showcasing their progression and succession to the top of this sport. After going through several options I decided to use Python as the preferred language to tell this story.

And here is the story ! Slam race from year 2008 - 2021.

<div class="4u"><span class="image fit"><img src="{{ "/images/BeautifulSoup/slamrace.gif" | absolute_url }}" alt="" /></span></div>

<h2>Why Beautiful Soup?</h2>
<span class="image right"><img src="{{ "/images/BeautifulSoup/BSlogo.jpeg" | absolute_url }}" alt="" /></span> 
Objective for me was to get complete and accurate trend visual, and to get this data from a reliable source, in this case was ATP website, since online repository has history of all tennis players and matches for all tournaments. But how to quickly navigate through web and get this extracted into a sample set? Enters Beautiful Soup, for a quick project turnaround and to scrape literally anything you give to your parser, this library provided by Python is the most diverse package you can ask for. 
- Beautiful Soup makes tree traverse, searching etc. very easy.
- It automatically converts encoding types to best suit your need.
- It sits on top of other Python libraries like lxml and html5lib

Many big data and data science projects require web scraping and this library helps developers, the name of the package was inspired from a song in <i>Alice's Advantures In The Wonderland</i>

<div class="4u"><span class="image fit"><img src="{{ "/images/BeautifulSoup/bsoupref.jpg" | absolute_url }}" alt="" /></span></div>

<h3>Inspecting Web Page </h3>
They key to gathering information from web is understanding tree structure of your target webpage. This helps in extracting information such as query pattern, HTML table content etc. You can use any browser tool to get HTML content view, I used Chrome's Inspect Element feature. 

<span class="image fit"><img src="{{ "/images/BeautifulSoup/Inspect.png" | absolute_url }}" alt="" /></span>

You can inspect DOM and CSS pattern using this feature and understand page tree structure.

<h3>Data Manipulation & Visualization </h3>
Extracting data from a site majority of time would also require transformation. Extracted data needs to be cleaned further for analytics and visualization purpose. This example uses pandas, bar_chart_race and pandas_alive package to achieve these steps.

<h3>Implementation Steps</h3>
<ul>
    <li>Use request library to initiate URL connection</li>
    <li>Use beautiful soup library to find html content from the page</li>
    <li>Store extract in Dataframe using Pandas</li>
    <li>Use race chart and pandas alive library to create a gif and video extract of the data</li>
</ul>

<script src="https://gist.github.com/abhi2020-ds/6c86e36af0ab054d4480cb7d6a973f49.js"></script>

<hr /> 
<div class="row">
    <div class="6u 12u$(small)">
        <h3>References</h3>
        <ul>
            <li><a href="https://bookdown.org/yihui/rmarkdown/">R Markdown</a></li>
            <li><a href="https://support.rstudio.com/hc/en-us/articles/200486468-Authoring-R-Presentations">R Presentations</a></li>
        </ul>
    </div>
    </div>
    
